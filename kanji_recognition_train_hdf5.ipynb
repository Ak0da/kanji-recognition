{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a461a11-da97-4cf4-bf9b-83249734fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hub\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from typing import Callable\n",
    "import csv\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116c5401-d0db-4875-beaa-f27bcd4c7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "nb_symbols = 2199\n",
    "\n",
    "from kanji_detection_model import kanji_detector\n",
    "\n",
    "    \n",
    "def getModel():\n",
    "    return kanji_detector()\n",
    "\n",
    "\n",
    "def testModel():\n",
    "    modelRunnable = getModel().to(device=device)\n",
    "    print(modelRunnable)\n",
    "    \n",
    "    summary1 = summary(\n",
    "        modelRunnable,\n",
    "        input_size=[\n",
    "            (20, 1, image_size, image_size)\n",
    "        ],\n",
    "        dtypes=[torch.double, torch.double],\n",
    "        depth=3\n",
    "    )\n",
    "    \n",
    "    print(summary1)\n",
    "    \n",
    "    del modelRunnable\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7d1999-312c-45dc-a59a-5b68ed1b4eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated : 0\n",
      "Reserved : 0\n",
      "Allocated : 0\n",
      "Reserved : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Allocated : \" + str(torch.cuda.memory_allocated()))\n",
    "print(\"Reserved : \" + str(torch.cuda.memory_reserved()))\n",
    "\n",
    "#testModel()\n",
    "#start = time.time()\n",
    "print(\"Allocated : \" + str(torch.cuda.memory_allocated()))\n",
    "print(\"Reserved : \" + str(torch.cuda.memory_reserved()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cd556f-bad7-4022-baf5-d978b59475b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train = 0\n",
    "length_eval = 0\n",
    "\n",
    "train_set = {}\n",
    "eval_set = {}\n",
    "train_labels = {}\n",
    "eval_labels = {}\n",
    "\n",
    "f = h5py.File('image_set.hdf5', 'r')\n",
    "\n",
    "train_set = f['training_group']['dataset']\n",
    "eval_set = f['evaluation_group']['dataset']\n",
    "train_labels = f['training_group']['labels']\n",
    "eval_labels = f['evaluation_group']['labels']\n",
    "#print(train_set[0])\n",
    "\n",
    "train_index_list = [i for i in range(train_set.shape[0])]\n",
    "eval_index_list = [i for i in range(eval_set.shape[0])]\n",
    "\n",
    "random.shuffle(train_index_list)\n",
    "random.shuffle(eval_index_list)\n",
    "\n",
    "#picturesNames = [f for f in listdir(trainingPath) if isfile(join(trainingPath, f))]\n",
    "#g_dictNames = {name:{'name':name , 'number':int(name.split('_')[0]) , 'symbol':name.split('_')[1]} for name in picturesNames}\n",
    "#shufflePicturesNames = picturesNames.copy()\n",
    "#random.shuffle(shufflePicturesNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcee1a34-6067-4de2-af73-6a210aaa8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KanjiImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, delimiter=',', header=0)\n",
    "        #print(self.img_labels)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        #image = read_image(img_path)\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = KanjiImageDataset(\"loader_data_train.csv\", \".\\Training_set\", img_transform, int)\n",
    "evaluation_data = KanjiImageDataset(\"loader_data_eval.csv\", \".\\Training_set\", img_transform, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386967c9-a5f4-4b75-931e-9e645db03ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectorIndexTrain = [0]\n",
    "selectorIndexEval = [0]\n",
    "def selectBatches(batch_size: int, isTraining: bool) -> list:\n",
    "    global selectorIndexTrain\n",
    "    global selectorIndexEval\n",
    "    global train_index_list\n",
    "    global eval_index_list\n",
    "    \n",
    "    true_list_len = len(train_index_list) if isTraining else len(eval_index_list)\n",
    "    index_list = train_index_list if isTraining else eval_index_list\n",
    "    selector_index = selectorIndexTrain if isTraining else selectorIndexEval\n",
    "    \n",
    "    selected_indices = []\n",
    "    while len(selected_indices) < batch_size:\n",
    "        list_len = true_list_len - selector_index[0]\n",
    "        n_to_find = batch_size - len(selected_indices)\n",
    "        start = selector_index[0]\n",
    "        \n",
    "        if list_len >= n_to_find:\n",
    "            end = selector_index[0]+n_to_find\n",
    "            selected_indices.extend(index_list[start:end])\n",
    "            selector_index[0] += n_to_find\n",
    "        else:\n",
    "            selected_indices.extend(index_list[start:])\n",
    "            random.shuffle(index_list)\n",
    "            selector_index[0] = 0\n",
    "    \n",
    "    #print(str(batch[0]) +\" \"+ str(batch[99]))\n",
    "    #print(batch_size)\n",
    "    #print(len(batch))\n",
    "    \n",
    "    dataset = train_set if isTraining else eval_set\n",
    "    labels = train_labels if isTraining else eval_labels\n",
    "    \n",
    "    images = np.array([dataset[index] for index in selected_indices])\n",
    "    selected_labels = torch.LongTensor([labels[index,0] for index in selected_indices])\n",
    "    \n",
    "    return (torch.FloatTensor(images)/255).unsqueeze(1), selected_labels-1\n",
    "\n",
    "\n",
    "#def countCorrect(answer: torch.FloatTensor, correctAnswer: torch.FloatTensor):\n",
    "def countCorrect(answer: torch.FloatTensor, correctAnswerIndices: torch.FloatTensor):\n",
    "    \n",
    "    _,indicesAnswer = torch.max(answer, dim=1)\n",
    "    \n",
    "    #print(indicesAnswer)\n",
    "    #print(indicesCorrect)\n",
    "    numCorrect = (indicesAnswer == correctAnswerIndices).long().sum()\n",
    "    \n",
    "    return numCorrect.item()\n",
    "\n",
    "#def countTop5Correct(answer: torch.FloatTensor, correctAnswer: torch.FloatTensor):\n",
    "def countTop5Correct(answer: torch.FloatTensor, correctAnswerIndices: torch.FloatTensor):\n",
    "    _,indicesAnswer = answer.topk(k=5, dim=1)\n",
    "    \n",
    "    #print(indicesAnswer.shape)\n",
    "    #print(correctAnswerIndices.shape)\n",
    "    numCorrect = (indicesAnswer == correctAnswerIndices.unsqueeze(-1)).long().sum()\n",
    "    \n",
    "    return numCorrect.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5314d7b-a246-43c3-9bd4-b84dbec96dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, n_epoch, batch_size, lr: Callable[[int], float]):\n",
    "    global timer1\n",
    "    global timer2\n",
    "    global timer3\n",
    "    \n",
    "    n_batches = 100\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr(0))\n",
    "    \n",
    "    frequency_detailed_results = 5\n",
    "    \n",
    "    model.train()\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    best_percent = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        n_correct_1_t = 0\n",
    "        n_correct_5_t = 0\n",
    "        n_correct_1_e = 0\n",
    "        n_correct_5_e = 0\n",
    "        \n",
    "        n_total = n_batches*batch_size\n",
    "        t_loss = 0\n",
    "        \n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr(epoch)\n",
    "        #model.zero_grad()\n",
    "            \n",
    "        time_select = 0 #debug\n",
    "        time_model = 0 #debug\n",
    "        \n",
    "        start_epoch = time.time()\n",
    "            \n",
    "        print(\"Epoch \" + str(epoch+1))\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "\n",
    "            model.zero_grad()\n",
    "            #optimizer.zero_grad() not needed ?\n",
    "            \n",
    "            start = time.time() #debug\n",
    "            images, labels = selectBatches(batch_size, isTraining=True)\n",
    "            #print(images.shape)\n",
    "            #images, correct_answer_indices = next(iter(dataloader_train))\n",
    "            end = time.time() #debug\n",
    "            time_select += end-start # debug\n",
    "            \n",
    "            start = time.time() #debug\n",
    "            answer = model(images.to(device=device))\n",
    "            end = time.time() #debug\n",
    "            time_model += end-start # debug\n",
    "            \n",
    "            loss = loss_f(answer,labels.to(device=device)).cpu()\n",
    "            t_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step() #Trying at the end of the epoch ?\n",
    "            \n",
    "            if (epoch+1) % frequency_detailed_results == 0:\n",
    "                #images_eval, correct_answer_indices_eval = next(iter(dataloader_eval))\n",
    "                #answer_eval = model(images_eval.to(device=device))\n",
    "                images_eval, labels_eval = selectBatches(batch_size, isTraining=True)\n",
    "                answer_eval = model(images_eval.to(device=device))\n",
    "                \n",
    "                n_correct_1_t += countCorrect(answer, labels.to(device=device))\n",
    "                n_correct_5_t += countTop5Correct(answer, labels.to(device=device))\n",
    "                n_correct_1_e += countCorrect(answer_eval, labels_eval.to(device=device))\n",
    "                n_correct_5_e += countTop5Correct(answer_eval, labels_eval.to(device=device))\n",
    "            \n",
    "            \n",
    "            #print(loss.item())\n",
    "            #print(torch.softmax(answer,dim=1))\n",
    "            #print(correct_answer)\n",
    "            #print(n_correct)\n",
    "        \n",
    "        #optimizer.step()\n",
    "        adjust = 100\n",
    "        percent_1_t = math.floor(adjust*100*n_correct_1_t/n_total)/adjust\n",
    "        percent_5_t = math.floor(adjust*100*n_correct_5_t/n_total)/adjust\n",
    "        percent_1_e = math.floor(adjust*100*n_correct_1_e/n_total)/adjust\n",
    "        percent_5_e = math.floor(adjust*100*n_correct_5_e/n_total)/adjust\n",
    "        \n",
    "        display_loss = math.floor(adjust*t_loss)/adjust\n",
    "        \n",
    "        best_percent = percent_5_e if percent_5_e > best_percent else best_percent\n",
    "        \n",
    "        end_epoch = time.time()\n",
    "        time_epoch = end_epoch-start_epoch\n",
    "        \n",
    "        #print(\"Time epoch : \" + str(math.floor(time_epoch*adjust)/adjust)) #debug\n",
    "        #print(\"\\tTime select : \" + str(math.floor(time_select*adjust)/adjust)) #debug\n",
    "        #print(\"\\tTime model : \" + str(math.floor(time_model*adjust)/adjust)) #debug\n",
    "        \n",
    "        \n",
    "        timer1 = 0\n",
    "        timer2 = 0\n",
    "        timer3 = 0\n",
    "        \n",
    "        print(\"\\tLoss : \" + str(display_loss))\n",
    "        \n",
    "        if (epoch+1) % frequency_detailed_results == 0:\n",
    "            print(\"\\tTop-1 training accuracy : \" + str(percent_1_t) + \"%\")\n",
    "            print(\"\\tTop-5 training accuracy : \" + str(percent_5_t) + \"%\")\n",
    "            print(\"\\tTop-1 evaluation accuracy : \" + str(percent_1_e) + \"%\")\n",
    "            print(\"\\tTop-5 evaluation accuracy : \" + str(percent_5_e) + \"%\")\n",
    "        \n",
    "        if percent_5_e > 98.0:\n",
    "            break\n",
    "        \n",
    "        print(\"\")\n",
    "        \n",
    "    return best_percent\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "    \n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445cd069-0390-43dc-995d-f32de01ae500",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [100] #[25, 50, 100, 150, 200]\n",
    "learning_rates = [0.00001] #[0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bb27e5-97c7-4a2f-9343-4d794c6c67e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor bs in batch_sizes:\\n    for lr in learning_rates:\\n        trainModel = getModel().to(device=device)\\n        weights_init(trainModel)\\n        percent = train(trainModel, n_epochs, bs, lr)\\n        print(\"bs=\" + str(bs) + \" lr=\" + str(lr) + \" : \" + str(percent) + \"%\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for bs in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        trainModel = getModel().to(device=device)\n",
    "        weights_init(trainModel)\n",
    "        percent = train(trainModel, n_epochs, bs, lr)\n",
    "        print(\"bs=\" + str(bs) + \" lr=\" + str(lr) + \" : \" + str(percent) + \"%\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e18acd8-cace-4be2-b033-a74c868122d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "\n",
      "Epoch 1\n",
      "Time epoch : 1.76\n",
      "\tTime select : 0.43\n",
      "\tTime model : 0.55\n",
      "\tLoss : 769.73\n",
      "\n",
      "Epoch 2\n",
      "Time epoch : 1.46\n",
      "\tTime select : 0.44\n",
      "\tTime model : 0.43\n",
      "\tLoss : 769.64\n",
      "\n",
      "Epoch 3\n",
      "Time epoch : 1.53\n",
      "\tTime select : 0.53\n",
      "\tTime model : 0.42\n",
      "\tLoss : 769.73\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModel = getModel().to(device=device)\n",
    "weights_init(trainModel)\n",
    "n_epochs = 3\n",
    "\n",
    "#lr: Callable[[int], float] = lambda epoch: 0.0003\n",
    "lr: Callable[[int], float] = lambda epoch: 0.0005/(1.002**epoch)\n",
    "\n",
    "print(\"Running on \" + device + \"\\n\")\n",
    "#train(trainModel, n_epochs, batch_sizes[0], learning_rates[0])\n",
    "train(trainModel, n_epochs, 100, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "483c9952-180c-4095-822c-5e45f278377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel.eval()\n",
    "\n",
    "torch.save(trainModel.cpu(),\"./Models/kanji_model_v5_top5_88_eval.pt\")\n",
    "\n",
    "torch.save(trainModel.cpu().state_dict(), \"./Models/kanji_model_v5_top5_88_eval.pth\")\n",
    "\n",
    "#temp = torch.jit.script(trainModel.cpu())\n",
    "#torch.jit.save(temp, \"./Models/kanji_model_96_1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a662c-901a-49f3-b937-6766ed490b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
