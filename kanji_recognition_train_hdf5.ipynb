{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a461a11-da97-4cf4-bf9b-83249734fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hub\\util\\check_latest_version.py:32: UserWarning: A newer version of hub (2.6.0) is available. It's recommended that you update to the latest version using `pip install -U hub`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from typing import Callable\n",
    "import csv\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "all_settings = {\n",
    "    'kanji' : {\n",
    "        'script_name' : 'kanji',\n",
    "        'filename':'image_set_kanji.hdf5',\n",
    "        'number_symbols' : 3149\n",
    "    },\n",
    "    \n",
    "    'hangul' : {\n",
    "        'script_name' : 'hangul',\n",
    "        'filename':'image_set_hangul.hdf5',\n",
    "        'number_symbols' : 2028\n",
    "    }\n",
    "}\n",
    "            \n",
    "settings = all_settings['kanji']\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116c5401-d0db-4875-beaa-f27bcd4c7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "nb_symbols = settings['number_symbols']\n",
    "\n",
    "from kanji_detection_model import kanji_detector\n",
    "\n",
    "    \n",
    "def getModel():\n",
    "    return kanji_detector(nb_symbols)\n",
    "\n",
    "\n",
    "def testModel():\n",
    "    modelRunnable = getModel().to(device=device)\n",
    "    print(modelRunnable)\n",
    "    \n",
    "    summary1 = summary(\n",
    "        modelRunnable,\n",
    "        input_size=[\n",
    "            (20, 1, image_size, image_size)\n",
    "        ],\n",
    "        dtypes=[torch.double, torch.double],\n",
    "        depth=3\n",
    "    )\n",
    "    \n",
    "    print(summary1)\n",
    "    \n",
    "    del modelRunnable\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0001ddc3-f0f7-4c89-b5d8-c280a90e1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSelectionDataset = 0\n",
    "class KanjiRandomImageCustomLoader():\n",
    "    def __init__(self, hdf5_file_name: str, batch_size: int, isTraining:bool, transform=None, target_transform=None):\n",
    "        self.f = h5py.File(hdf5_file_name, 'r')\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.group = 'training_group' if isTraining else 'evaluation_group'\n",
    "        self.dataset = self.f[self.group]['dataset']\n",
    "        self.labels = self.f[self.group]['labels']\n",
    "        \n",
    "        self.index_list = [i for i in range(self.dataset.shape[0])]\n",
    "        random.shuffle(self.index_list)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.selector_index = 0\n",
    "        \n",
    "        self.resetNeeded = True\n",
    "    \n",
    "    def needsReset(sefl)->bool:\n",
    "        return self.resetNeeded\n",
    "    \n",
    "    def reset(self):\n",
    "        self.selector_index = 0\n",
    "        random.shuffle(self.index_list)\n",
    "        self.resetNeeded = False\n",
    "    \n",
    "    def getIndexValue(self) -> int:\n",
    "        return self.selector_index\n",
    "\n",
    "    def getNextBatch(self):\n",
    "        global timeSelectionDataset\n",
    "        \n",
    "        true_list_len = len(self.index_list)\n",
    "        selected_index = -1\n",
    "        list_len = true_list_len - self.selector_index\n",
    "        \n",
    "        selected_indices = []\n",
    "        while len(selected_indices) < self.batch_size:\n",
    "            list_len = true_list_len - self.selector_index\n",
    "            n_to_find = self.batch_size - len(selected_indices)\n",
    "            start = self.selector_index\n",
    "\n",
    "            if list_len >= n_to_find:\n",
    "                end = self.selector_index + n_to_find\n",
    "                selected_indices.extend(self.index_list[start:end])\n",
    "                self.selector_index += n_to_find\n",
    "            else:\n",
    "                self.resetNeeded = True\n",
    "                selected_indices.extend(self.index_list[start:])\n",
    "                random.shuffle(self.index_list)\n",
    "                self.selector_index = 0\n",
    "    \n",
    "        #print(str(batch[0]) +\" \"+ str(batch[99]))\n",
    "        #print(batch_size)\n",
    "        #print(len(batch))\n",
    "        \n",
    "        labels = torch.LongTensor([self.labels[index,0] for index in selected_indices])\n",
    "        \n",
    "        start=time.time() #debug\n",
    "        images = np.array([self.dataset[index] for index in selected_indices])\n",
    "        end=time.time() #debug\n",
    "        timeSelectionDataset+=end-start  #debug\n",
    "        \n",
    "        #selected_indices.sort()\n",
    "        #np_indices = np.array(selected_indices)\n",
    "        #images = self.dataset[np_indices]\n",
    "        \n",
    "        \n",
    "        images = (torch.as_tensor(images,dtype=torch.float)/255).unsqueeze(1)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "        if self.target_transform:\n",
    "            labels = self.target_transform(labels)\n",
    "            \n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1909cc76-8b1e-468c-81d8-26db11da1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countCorrect(answer: torch.FloatTensor, correctAnswerIndices: torch.FloatTensor):\n",
    "    \n",
    "    _,indicesAnswer = torch.max(answer, dim=1)\n",
    "    \n",
    "    #print(indicesAnswer)\n",
    "    #print(indicesCorrect)\n",
    "    numCorrect = (indicesAnswer == correctAnswerIndices).long().sum()\n",
    "    \n",
    "    return numCorrect.item()\n",
    "\n",
    "def countTop5Correct(answer: torch.FloatTensor, correctAnswerIndices: torch.FloatTensor):\n",
    "    _,indicesAnswer = answer.topk(k=5, dim=1)\n",
    "    \n",
    "    #print(indicesAnswer.shape)\n",
    "    #print(correctAnswerIndices.shape)\n",
    "    numCorrect = (indicesAnswer == correctAnswerIndices.unsqueeze(-1)).long().sum()\n",
    "    \n",
    "    return numCorrect.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5314d7b-a246-43c3-9bd4-b84dbec96dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, n_epoch, batch_size, lr: Callable[[int], float]):\n",
    "    \n",
    "    global timeSelectionDataset\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr(0))\n",
    "    \n",
    "    custom_loader_train = KanjiRandomImageCustomLoader(settings['filename'], batch_size=batch_size, isTraining=True)\n",
    "    custom_loader_eval = KanjiRandomImageCustomLoader(settings['filename'], batch_size=batch_size, isTraining=False)\n",
    "    \n",
    "    frequency_detailed_results = 5\n",
    "    \n",
    "    model.train()\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    best_percent = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        n_correct_1_t = 0\n",
    "        n_correct_5_t = 0\n",
    "        n_correct_1_e = 0\n",
    "        n_correct_5_e = 0\n",
    "        \n",
    "        n_total = 0\n",
    "        t_loss = 0\n",
    "        \n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr(epoch)\n",
    "        #model.zero_grad()\n",
    "            \n",
    "        time_select = 0 #debug\n",
    "        time_model = 0 #debug\n",
    "        timeSelectionDataset = 0 # debug\n",
    "        start_epoch = time.time() #debug\n",
    "            \n",
    "        print(\"Epoch \" + str(epoch+1))\n",
    "        custom_loader_train.reset()\n",
    "        \n",
    "        while not custom_loader_train.resetNeeded:\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            #optimizer.zero_grad() not needed ?\n",
    "            \n",
    "            start = time.time() #debug\n",
    "            images, labels = custom_loader_train.getNextBatch()\n",
    "            end = time.time() #debug\n",
    "            time_select += end-start # debug\n",
    "            \n",
    "            start = time.time() #debug\n",
    "            answer = model(images.to(device=device))\n",
    "            end = time.time() #debug\n",
    "            time_model += end-start # debug\n",
    "            \n",
    "            loss = loss_f(answer,labels.to(device=device)).cpu()\n",
    "            t_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step() #Trying at the end of the epoch ?\n",
    "            n_total += batch_size\n",
    "            \n",
    "            #print(custom_loader_train.getIndexValue())\n",
    "            #print(custom_loader_train.needsReset)\n",
    "            \n",
    "            if (epoch+1) % frequency_detailed_results == 0:\n",
    "                model.eval()\n",
    "                images_eval, labels_eval = custom_loader_eval.getNextBatch()\n",
    "                answer_eval = model(images_eval.to(device=device))\n",
    "                \n",
    "                n_correct_1_t += countCorrect(answer, labels.to(device=device))\n",
    "                n_correct_5_t += countTop5Correct(answer, labels.to(device=device))\n",
    "                n_correct_1_e += countCorrect(answer_eval, labels_eval.to(device=device))\n",
    "                n_correct_5_e += countTop5Correct(answer_eval, labels_eval.to(device=device))\n",
    "        \n",
    "        adjust = 100\n",
    "        percent_1_t = math.floor(adjust*100*n_correct_1_t/n_total)/adjust\n",
    "        percent_5_t = math.floor(adjust*100*n_correct_5_t/n_total)/adjust\n",
    "        percent_1_e = math.floor(adjust*100*n_correct_1_e/n_total)/adjust\n",
    "        percent_5_e = math.floor(adjust*100*n_correct_5_e/n_total)/adjust\n",
    "        \n",
    "        display_loss = math.floor(adjust*t_loss)/adjust\n",
    "        \n",
    "        best_percent = percent_5_e if percent_5_e > best_percent else best_percent\n",
    "        \n",
    "        end_epoch = time.time()\n",
    "        time_epoch = end_epoch-start_epoch\n",
    "        \n",
    "        \n",
    "        timeSelection=0\n",
    "        print(\"Time epoch : \" + str(math.floor(time_epoch*adjust)/adjust) + \"s\") #debug\n",
    "        \n",
    "        #print(\"\\tTime select : \" + str(math.floor(time_select*adjust)/adjust)) #debug\n",
    "        #print(\"\\t - Time select (inside) : \" + str(math.floor(timeSelectionDataset*adjust)/adjust)) #debug\n",
    "        #print(\"\\tTime model : \" + str(math.floor(time_model*adjust)/adjust)) #debug\n",
    "        \n",
    "        \n",
    "        timer1 = 0\n",
    "        timer2 = 0\n",
    "        timer3 = 0\n",
    "        \n",
    "        print(\"\\tLoss : \" + str(display_loss))\n",
    "        \n",
    "        if (epoch+1) % frequency_detailed_results == 0:\n",
    "            print(\"\\tTop-1 training accuracy : \" + str(percent_1_t) + \"%\")\n",
    "            print(\"\\tTop-5 training accuracy : \" + str(percent_5_t) + \"%\")\n",
    "            print(\"\\tTop-1 evaluation accuracy : \" + str(percent_1_e) + \"%\")\n",
    "            print(\"\\tTop-5 evaluation accuracy : \" + str(percent_5_e) + \"%\")\n",
    "        \n",
    "        if percent_5_e > 96.0:\n",
    "            break\n",
    "        \n",
    "        print(\"\")\n",
    "        \n",
    "    return best_percent\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "    \n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e18acd8-cace-4be2-b033-a74c868122d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n",
      "\n",
      "Epoch 1\n",
      "Time epoch : 80.37s\n",
      "\tLoss : 26883.68\n",
      "\n",
      "Epoch 2\n",
      "Time epoch : 33.39s\n",
      "\tLoss : 16341.79\n",
      "\n",
      "Epoch 3\n",
      "Time epoch : 33.51s\n",
      "\tLoss : 9691.92\n",
      "\n",
      "Epoch 4\n",
      "Time epoch : 33.79s\n",
      "\tLoss : 6750.62\n",
      "\n",
      "Epoch 5\n",
      "Time epoch : 66.83s\n",
      "\tLoss : 5060.17\n",
      "\tTop-1 training accuracy : 63.22%\n",
      "\tTop-5 training accuracy : 85.79%\n",
      "\tTop-1 evaluation accuracy : 57.99%\n",
      "\tTop-5 evaluation accuracy : 82.1%\n",
      "\n",
      "Epoch 6\n",
      "Time epoch : 31.73s\n",
      "\tLoss : 3981.48\n",
      "\n",
      "Epoch 7\n",
      "Time epoch : 31.65s\n",
      "\tLoss : 3231.89\n",
      "\n",
      "Epoch 8\n",
      "Time epoch : 32.37s\n",
      "\tLoss : 2665.0\n",
      "\n",
      "Epoch 9\n",
      "Time epoch : 32.62s\n",
      "\tLoss : 2257.34\n",
      "\n",
      "Epoch 10\n",
      "Time epoch : 66.19s\n",
      "\tLoss : 1927.14\n",
      "\tTop-1 training accuracy : 83.8%\n",
      "\tTop-5 training accuracy : 96.71%\n",
      "\tTop-1 evaluation accuracy : 74.21%\n",
      "\tTop-5 evaluation accuracy : 92.21%\n",
      "\n",
      "Epoch 11\n",
      "Time epoch : 33.64s\n",
      "\tLoss : 1667.8\n",
      "\n",
      "Epoch 12\n",
      "Time epoch : 31.67s\n",
      "\tLoss : 1462.96\n",
      "\n",
      "Epoch 13\n",
      "Time epoch : 31.59s\n",
      "\tLoss : 1282.81\n",
      "\n",
      "Epoch 14\n",
      "Time epoch : 31.75s\n",
      "\tLoss : 1156.74\n",
      "\n",
      "Epoch 15\n",
      "Time epoch : 60.36s\n",
      "\tLoss : 1003.78\n",
      "\tTop-1 training accuracy : 90.9%\n",
      "\tTop-5 training accuracy : 98.99%\n",
      "\tTop-1 evaluation accuracy : 78.86%\n",
      "\tTop-5 evaluation accuracy : 94.47%\n",
      "\n",
      "Epoch 16\n",
      "Time epoch : 31.83s\n",
      "\tLoss : 908.7\n",
      "\n",
      "Epoch 17\n",
      "Time epoch : 31.75s\n",
      "\tLoss : 819.46\n",
      "\n",
      "Epoch 18\n",
      "Time epoch : 31.48s\n",
      "\tLoss : 732.16\n",
      "\n",
      "Epoch 19\n",
      "Time epoch : 31.61s\n",
      "\tLoss : 666.62\n",
      "\n",
      "Epoch 20\n",
      "Time epoch : 61.2s\n",
      "\tLoss : 612.34\n",
      "\tTop-1 training accuracy : 94.21%\n",
      "\tTop-5 training accuracy : 99.61%\n",
      "\tTop-1 evaluation accuracy : 80.99%\n",
      "\tTop-5 evaluation accuracy : 95.21%\n",
      "\n",
      "Epoch 21\n",
      "Time epoch : 33.52s\n",
      "\tLoss : 549.91\n",
      "\n",
      "Epoch 22\n",
      "Time epoch : 31.59s\n",
      "\tLoss : 502.76\n",
      "\n",
      "Epoch 23\n",
      "Time epoch : 31.72s\n",
      "\tLoss : 465.04\n",
      "\n",
      "Epoch 24\n",
      "Time epoch : 31.62s\n",
      "\tLoss : 429.61\n",
      "\n",
      "Epoch 25\n",
      "Time epoch : 60.79s\n",
      "\tLoss : 383.1\n",
      "\tTop-1 training accuracy : 96.33%\n",
      "\tTop-5 training accuracy : 99.85%\n",
      "\tTop-1 evaluation accuracy : 82.19%\n",
      "\tTop-5 evaluation accuracy : 95.67%\n",
      "\n",
      "Epoch 26\n",
      "Time epoch : 31.54s\n",
      "\tLoss : 363.11\n",
      "\n",
      "Epoch 27\n",
      "Time epoch : 31.98s\n",
      "\tLoss : 329.66\n",
      "\n",
      "Epoch 28\n",
      "Time epoch : 32.08s\n",
      "\tLoss : 308.47\n",
      "\n",
      "Epoch 29\n",
      "Time epoch : 32.91s\n",
      "\tLoss : 289.25\n",
      "\n",
      "Epoch 30\n",
      "Time epoch : 63.09s\n",
      "\tLoss : 262.25\n",
      "\tTop-1 training accuracy : 97.46%\n",
      "\tTop-5 training accuracy : 99.94%\n",
      "\tTop-1 evaluation accuracy : 82.98%\n",
      "\tTop-5 evaluation accuracy : 95.94%\n",
      "\n",
      "Epoch 31\n",
      "Time epoch : 32.35s\n",
      "\tLoss : 245.86\n",
      "\n",
      "Epoch 32\n",
      "Time epoch : 31.16s\n",
      "\tLoss : 230.53\n",
      "\n",
      "Epoch 33\n",
      "Time epoch : 32.88s\n",
      "\tLoss : 215.55\n",
      "\n",
      "Epoch 34\n",
      "Time epoch : 32.67s\n",
      "\tLoss : 198.63\n",
      "\n",
      "Epoch 35\n",
      "Time epoch : 63.93s\n",
      "\tLoss : 188.43\n",
      "\tTop-1 training accuracy : 98.19%\n",
      "\tTop-5 training accuracy : 99.97%\n",
      "\tTop-1 evaluation accuracy : 83.57%\n",
      "\tTop-5 evaluation accuracy : 96.1%\n"
     ]
    }
   ],
   "source": [
    "trainModel = getModel().to(device=device)\n",
    "weights_init(trainModel)\n",
    "n_epochs = 150\n",
    "\n",
    "#lr: Callable[[int], float] = lambda epoch: 0.0003\n",
    "#lr: Callable[[int], float] = lambda epoch: 0.0005/(1.002**epoch)\n",
    "#lr: Callable[[int], float] = lambda epoch: 0.0003/(1.002**epoch)\n",
    "lr: Callable[[int], float] = lambda epoch: 0.0003/(1.05**epoch) #Changed epoch meaning from there on\n",
    "\n",
    "print(\"Running on \" + device + \"\\n\")\n",
    "#train(trainModel, n_epochs, batch_sizes[0], learning_rates[0])\n",
    "percent = train(trainModel, n_epochs, 100, lr)\n",
    "#Best in 1.56s/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483c9952-180c-4095-822c-5e45f278377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel.eval()\n",
    "\n",
    "torch.save(trainModel.cpu(),'./Models/' +settings['script_name']+ '_model_v9_top5_96_eval.pt')\n",
    "\n",
    "torch.save(trainModel.cpu().state_dict(), './Models/' +settings['script_name']+ '_model_v9_top5_96_eval.pth')\n",
    "\n",
    "#temp = torch.jit.script(trainModel.cpu())\n",
    "#torch.jit.save(temp, \"./Models/kanji_model_96_1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a662c-901a-49f3-b937-6766ed490b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
