{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a461a11-da97-4cf4-bf9b-83249734fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hub\n",
    "import random\n",
    "import math\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "\n",
    "import pathlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "116c5401-d0db-4875-beaa-f27bcd4c7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "nb_symbols = 2199\n",
    "\n",
    "class kanji_detector(torch.nn.Module):\n",
    "    def __init__(self,dropout1=0.4, dropout2=0.2, dropout3=0.2):\n",
    "        super(kanji_detector, self).__init__()\n",
    "        self.sequence = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1,32,17),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout1),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(32,64,5),\n",
    "            torch.nn.Dropout(dropout2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(64,128,3),\n",
    "            torch.nn.Dropout(dropout3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(2048,512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512,nb_symbols),\n",
    "            #torch.nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.sequence(input)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def getModel():\n",
    "    return kanji_detector()\n",
    "\n",
    "\n",
    "def testModel():\n",
    "    modelRunnable = getModel().to(device=device)\n",
    "    print(modelRunnable)\n",
    "    \n",
    "    summary1 = summary(\n",
    "        modelRunnable,\n",
    "        input_size=[\n",
    "            (20, 1, image_size, image_size)\n",
    "        ],\n",
    "        dtypes=[torch.double, torch.double],\n",
    "        depth=3\n",
    "    )\n",
    "    \n",
    "    print(summary1)\n",
    "    \n",
    "    del modelRunnable\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7d1999-312c-45dc-a59a-5b68ed1b4eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated : 0\n",
      "Reserved : 0\n",
      "Allocated : 0\n",
      "Reserved : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Allocated : \" + str(torch.cuda.memory_allocated()))\n",
    "print(\"Reserved : \" + str(torch.cuda.memory_reserved()))\n",
    "\n",
    "#testModel()\n",
    "#start = time.time()\n",
    "print(\"Allocated : \" + str(torch.cuda.memory_allocated()))\n",
    "print(\"Reserved : \" + str(torch.cuda.memory_reserved()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386967c9-a5f4-4b75-931e-9e645db03ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingPath = pathlib.Path().resolve() / \"Training_set\"\n",
    "picturesNames = [f for f in listdir(trainingPath) if isfile(join(trainingPath, f))]\n",
    "\n",
    "dictNames = {name:{'number':int(name.split('_')[0]) , 'symbol':name.split('_')[1]} for name in picturesNames}\n",
    "tempDictNames = dictNames.copy()\n",
    "\n",
    "#print(dictNames[picturesNames[0]])\n",
    "\n",
    "def selectBatches(dictNames, tempDictNames, batch_size) -> list:\n",
    "    batch=[]\n",
    "    while len(batch) < batch_size:\n",
    "        n_to_find = batch_size-len(batch)\n",
    "        if len(tempDictNames) >= n_to_find:\n",
    "            sample = random.sample(list(tempDictNames.items()), n_to_find)\n",
    "            batch.extend(sample)\n",
    "            for item in sample:\n",
    "                del tempDictNames[item[0]]\n",
    "        else:\n",
    "            batch.extend(tempDictNames.items())\n",
    "            tempDictNames = dictNames.copy()\n",
    "\n",
    "    return batch\n",
    "\n",
    "def getAnswerIndices(batchList) -> torch.FloatTensor:\n",
    "    \n",
    "    correctAnswer = torch.zeros((len(batchList),nb_symbols)).float()\n",
    "    correctAnswerIndices = torch.zeros(len(batchList)).long()\n",
    "    \n",
    "    for i in range(len(batchList)):\n",
    "        indexCorrect = batchList[i][1]['number']-1\n",
    "        correctAnswer[i][indexCorrect] = 1\n",
    "        correctAnswerIndices[i] = indexCorrect\n",
    "    \n",
    "    \n",
    "    return correctAnswer, correctAnswerIndices\n",
    "\n",
    "def countCorrect(answer: torch.FloatTensor, correctAnswer: torch.FloatTensor):\n",
    "    \n",
    "    \n",
    "    _,indicesAnswer = torch.max(answer, dim=1)\n",
    "    _,indicesCorrect = torch.max(correctAnswer, dim=1)\n",
    "    \n",
    "    #print(indicesAnswer)\n",
    "    #print(indicesCorrect)\n",
    "    numCorrect = (indicesAnswer == indicesCorrect).long().sum()\n",
    "    \n",
    "    return numCorrect.item()\n",
    "    \n",
    "def getPictures(batchList) -> torch.FloatTensor:\n",
    "    \n",
    "    images = torch.zeros((len(batchList), 1, image_size, image_size)).float()\n",
    "    convert_tensor = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    for i in range(len(batchList)):\n",
    "        item = batchList[i]\n",
    "        filename = item[0]\n",
    "        img = Image.open(trainingPath / filename)\n",
    "        images[i,:,:,:] = convert_tensor(img)\n",
    "        \n",
    "    return images\n",
    "        \n",
    "#for i in range(100):\n",
    "#    print(len(selectBatches(dictNames, tempDictNames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5314d7b-a246-43c3-9bd4-b84dbec96dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, n_epoch, batch_size, lr):\n",
    "    n_batches = 100\n",
    "    \n",
    "\n",
    "    #dataset = datasets.ImageFolder(trainingPath, transform=transform)\n",
    "    #dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    best_percent = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        #print(\"Epoch \" + str(epoch+1) + \" is running\")\n",
    "        n_correct = 0\n",
    "        n_total = n_batches*batch_size\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr/(epoch+1)**0.5)\n",
    "        for i in range(n_batches):\n",
    "\n",
    "            model.zero_grad()\n",
    "            #optimizer.zero_grad()\n",
    "            batch = selectBatches(dictNames, tempDictNames, batch_size)\n",
    "            images = getPictures(batch)\n",
    "            correct_answer, correct_answer_indices = getAnswerIndices(batch)\n",
    "\n",
    "            answer = model(images.to(device=device))\n",
    "            loss = loss_f(answer,correct_answer_indices.to(device=device)).cpu()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n_correct += countCorrect(answer, correct_answer.to(device=device))\n",
    "            \n",
    "            #print(loss.item())\n",
    "            #print(torch.softmax(answer,dim=1))\n",
    "            #print(correct_answer)\n",
    "            #print(n_correct)\n",
    "\n",
    "        adjust = 10000\n",
    "        percent = math.floor(adjust*100*n_correct/n_total)/adjust\n",
    "        best_percent = percent if percent > best_percent else best_percent\n",
    "        print(\"Epoch \" + str(epoch+1) +\" training accuracy : \" + str(percent) + \"%\\n\")\n",
    "        \n",
    "    return best_percent\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "    \n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        m.weight.data.normal_(0, 0.02)\n",
    "        m.bias.data.normal_(0, 0.001)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445cd069-0390-43dc-995d-f32de01ae500",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [100] #[25, 50, 100, 150, 200]\n",
    "learning_rates = [0.00001] #[0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27bb27e5-97c7-4a2f-9343-4d794c6c67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy : 0.68%\n",
      "\n",
      "Epoch 2 training accuracy : 1.0%\n",
      "\n",
      "Epoch 3 training accuracy : 1.12%\n",
      "\n",
      "Epoch 4 training accuracy : 5.8%\n",
      "\n",
      "Epoch 5 training accuracy : 9.53%\n",
      "\n",
      "Epoch 6 training accuracy : 15.34%\n",
      "\n",
      "Epoch 7 training accuracy : 21.91%\n",
      "\n",
      "Epoch 8 training accuracy : 31.62%\n",
      "\n",
      "Epoch 9 training accuracy : 40.4%\n",
      "\n",
      "Epoch 10 training accuracy : 50.17%\n",
      "\n",
      "Epoch 11 training accuracy : 60.46%\n",
      "\n",
      "Epoch 12 training accuracy : 66.12%\n",
      "\n",
      "Epoch 13 training accuracy : 71.44%\n",
      "\n",
      "Epoch 14 training accuracy : 74.34%\n",
      "\n",
      "Epoch 15 training accuracy : 76.96%\n",
      "\n",
      "Epoch 16 training accuracy : 80.13%\n",
      "\n",
      "Epoch 17 training accuracy : 82.54%\n",
      "\n",
      "Epoch 18 training accuracy : 84.11%\n",
      "\n",
      "Epoch 19 training accuracy : 86.59%\n",
      "\n",
      "Epoch 20 training accuracy : 87.78%\n",
      "\n",
      "Epoch 21 training accuracy : 89.32%\n",
      "\n",
      "Epoch 22 training accuracy : 90.54%\n",
      "\n",
      "Epoch 23 training accuracy : 91.41%\n",
      "\n",
      "Epoch 24 training accuracy : 92.47%\n",
      "\n",
      "Epoch 25 training accuracy : 93.15%\n",
      "\n",
      "Epoch 26 training accuracy : 93.81%\n",
      "\n",
      "Epoch 27 training accuracy : 94.12%\n",
      "\n",
      "Epoch 28 training accuracy : 94.63%\n",
      "\n",
      "Epoch 29 training accuracy : 94.88%\n",
      "\n",
      "Epoch 30 training accuracy : 95.08%\n",
      "\n",
      "Epoch 31 training accuracy : 95.52%\n",
      "\n",
      "Epoch 32 training accuracy : 95.7%\n",
      "\n",
      "Epoch 33 training accuracy : 95.91%\n",
      "\n",
      "Epoch 34 training accuracy : 96.07%\n",
      "\n",
      "Epoch 35 training accuracy : 95.97%\n",
      "\n",
      "Epoch 36 training accuracy : 95.98%\n",
      "\n",
      "Epoch 37 training accuracy : 96.02%\n",
      "\n",
      "Epoch 38 training accuracy : 96.11%\n",
      "\n",
      "Epoch 39 training accuracy : 96.07%\n",
      "\n",
      "Epoch 40 training accuracy : 96.1%\n",
      "\n",
      "Epoch 41 training accuracy : 96.12%\n",
      "\n",
      "Epoch 42 training accuracy : 96.07%\n",
      "\n",
      "Epoch 43 training accuracy : 96.0%\n",
      "\n",
      "Epoch 44 training accuracy : 96.1%\n",
      "\n",
      "Epoch 45 training accuracy : 96.08%\n",
      "\n",
      "Epoch 46 training accuracy : 96.11%\n",
      "\n",
      "Epoch 47 training accuracy : 96.06%\n",
      "\n",
      "Epoch 48 training accuracy : 96.09%\n",
      "\n",
      "Epoch 49 training accuracy : 96.04%\n",
      "\n",
      "Epoch 50 training accuracy : 96.12%\n",
      "\n",
      "bs=100 lr=1e-05 : 96.12%\n"
     ]
    }
   ],
   "source": [
    "for bs in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        trainModel = getModel().to(device=device)\n",
    "        weights_init(trainModel)\n",
    "        percent = train(trainModel, n_epochs, bs, lr)\n",
    "        print(\"bs=\" + str(bs) + \" lr=\" + str(lr) + \" : \" + str(percent) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e18acd8-cace-4be2-b033-a74c868122d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy : 0.05%\n",
      "\n",
      "Epoch 2 training accuracy : 0.83%\n",
      "\n",
      "Epoch 3 training accuracy : 1.0%\n",
      "\n",
      "Epoch 4 training accuracy : 1.04%\n",
      "\n",
      "Epoch 5 training accuracy : 1.02%\n",
      "\n",
      "Epoch 6 training accuracy : 3.27%\n",
      "\n",
      "Epoch 7 training accuracy : 6.87%\n",
      "\n",
      "Epoch 8 training accuracy : 12.05%\n",
      "\n",
      "Epoch 9 training accuracy : 18.55%\n",
      "\n",
      "Epoch 10 training accuracy : 28.07%\n",
      "\n",
      "Epoch 11 training accuracy : 38.13%\n",
      "\n",
      "Epoch 12 training accuracy : 46.45%\n",
      "\n",
      "Epoch 13 training accuracy : 52.92%\n",
      "\n",
      "Epoch 14 training accuracy : 58.0%\n",
      "\n",
      "Epoch 15 training accuracy : 63.68%\n",
      "\n",
      "Epoch 16 training accuracy : 68.02%\n",
      "\n",
      "Epoch 17 training accuracy : 71.78%\n",
      "\n",
      "Epoch 18 training accuracy : 75.0%\n",
      "\n",
      "Epoch 19 training accuracy : 77.46%\n",
      "\n",
      "Epoch 20 training accuracy : 79.88%\n",
      "\n",
      "Epoch 21 training accuracy : 81.75%\n",
      "\n",
      "Epoch 22 training accuracy : 84.85%\n",
      "\n",
      "Epoch 23 training accuracy : 86.07%\n",
      "\n",
      "Epoch 24 training accuracy : 87.64%\n",
      "\n",
      "Epoch 25 training accuracy : 89.43%\n",
      "\n",
      "Epoch 26 training accuracy : 91.28%\n",
      "\n",
      "Epoch 27 training accuracy : 92.97%\n",
      "\n",
      "Epoch 28 training accuracy : 94.1%\n",
      "\n",
      "Epoch 29 training accuracy : 95.03%\n",
      "\n",
      "Epoch 30 training accuracy : 95.17%\n",
      "\n",
      "Epoch 31 training accuracy : 95.38%\n",
      "\n",
      "Epoch 32 training accuracy : 95.67%\n",
      "\n",
      "Epoch 33 training accuracy : 95.9%\n",
      "\n",
      "Epoch 34 training accuracy : 96.03%\n",
      "\n",
      "Epoch 35 training accuracy : 96.05%\n",
      "\n",
      "Epoch 36 training accuracy : 96.12%\n",
      "\n",
      "Epoch 37 training accuracy : 96.11%\n",
      "\n",
      "Epoch 38 training accuracy : 96.11%\n",
      "\n",
      "Epoch 39 training accuracy : 96.14%\n",
      "\n",
      "Epoch 40 training accuracy : 96.09%\n",
      "\n",
      "Epoch 41 training accuracy : 96.12%\n",
      "\n",
      "Epoch 42 training accuracy : 96.09%\n",
      "\n",
      "Epoch 43 training accuracy : 96.09%\n",
      "\n",
      "Epoch 44 training accuracy : 96.11%\n",
      "\n",
      "Epoch 45 training accuracy : 96.13%\n",
      "\n",
      "Epoch 46 training accuracy : 96.12%\n",
      "\n",
      "Epoch 47 training accuracy : 96.11%\n",
      "\n",
      "Epoch 48 training accuracy : 96.11%\n",
      "\n",
      "Epoch 49 training accuracy : 96.15%\n",
      "\n",
      "Epoch 50 training accuracy : 96.1%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModel = getModel().to(device=device)\n",
    "weights_init(trainModel)\n",
    "n_epochs = 50\n",
    "\n",
    "train(trainModel, n_epochs, batch_sizes[0], learning_rates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "483c9952-180c-4095-822c-5e45f278377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainModel,\"Models/kanji_model_96_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d6b46-1abf-4662-a1f4-6a337002b784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ce0e3-3e01-48f9-b67a-7afbfa869be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1d3bb-5d47-4c3b-8731-64313a8d597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd3a77f8-196c-40e2-8518-c0b6486eb4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kanji_detector(\n",
      "  (sequence): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(17, 17), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=512, out_features=2199, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "evalModel = torch.load('kanji_model_96_1.pt', map_location=torch.device(device))\n",
    "print(evalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91669ce-682c-4f27-872b-a4b1a2c4bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, n_epoch, batch_size):\n",
    "    n_batches = 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "        loss_f = torch.nn.CrossEntropyLoss()\n",
    "        best_percent = 0\n",
    "        for epoch in range(n_epoch):\n",
    "            #print(\"Epoch \" + str(epoch+1) + \" is running\")\n",
    "            n_correct = 0\n",
    "            n_total = n_batches*batch_size\n",
    "            for i in range(n_batches):\n",
    "\n",
    "                batch = selectBatches(dictNames, tempDictNames, batch_size)\n",
    "                images = getPictures(batch)\n",
    "                correct_answer, correct_answer_indices = getAnswerIndices(batch)\n",
    "\n",
    "                answer = model(images.to(device=device))\n",
    "                loss = loss_f(answer,correct_answer_indices.to(device=device)).cpu()\n",
    "\n",
    "                print(answer)\n",
    "                n_correct += countCorrect(answer, correct_answer.to(device=device))\n",
    "\n",
    "            adjust = 10000\n",
    "            percent = math.floor(adjust*100*n_correct/n_total)/adjust\n",
    "            best_percent = percent if percent > best_percent else best_percent\n",
    "            print(\"Epoch \" + str(epoch+1) +\" evaluation accuracy : \" + str(percent) + \"%\\n\")\n",
    "        \n",
    "    return best_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9289481-c596-4553-9499-3b34095e9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7393, -3.0892, -4.2000,  ..., -3.7937, -4.1769, -3.1474],\n",
      "        [-4.2448, -2.5073, -4.6589,  ..., -3.3550, -4.6312, -3.9381],\n",
      "        [-2.0208, -2.3091, -3.8607,  ..., -3.7006, -4.2303, -2.8342],\n",
      "        ...,\n",
      "        [-2.2126, -2.3520, -3.3818,  ..., -3.5510, -2.9092, -2.8869],\n",
      "        [-2.5157, -2.2300, -3.7171,  ..., -3.9248, -3.3962, -3.0028],\n",
      "        [-3.4204, -3.6705, -4.8800,  ..., -4.4643, -5.3411, -5.0325]],\n",
      "       device='cuda:0')\n",
      "Epoch 1 evaluation accuracy : 96.0%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(trainModel,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fd5ec-3cc9-4aaa-8807-c5db4345f30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
